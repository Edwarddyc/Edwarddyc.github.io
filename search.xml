<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AI 开发技法</title>
    <url>/2026/01/20/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/</url>
    <content><![CDATA[<h1 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h1><p>本文档记录使用 LLM 的 AI 开发相关的技术总览，构建完整的 AI 开发流程。涉及到 LLM 的调用、基于 SpringAI 或者 LangChain4j 的具体 AI 开发。其中通过 Advisor、Prompt 和 RAG 来辅助和强化模型的能力。</p>
<ul>
<li>AI 大模型接入<ul>
<li>SDK</li>
<li>http</li>
<li>Spring AI or LangChain4j</li>
</ul>
</li>
<li>Prompt 工程<ul>
<li>基本概念</li>
<li>优化策略</li>
</ul>
</li>
<li>AI 应用方案设计<ul>
<li>ChatClient</li>
<li>Advisors</li>
</ul>
</li>
</ul>
<h1 id="AI-大模型接入"><a href="#AI-大模型接入" class="headerlink" title="AI 大模型接入"></a>AI 大模型接入</h1><h2 id="使用大模型的-2-种途径"><a href="#使用大模型的-2-种途径" class="headerlink" title="使用大模型的 2 种途径"></a>使用大模型的 2 种途径</h2><h3 id="1、云服务"><a href="#1、云服务" class="headerlink" title="1、云服务"></a>1、云服务</h3><p>直接使用云服务商在云端已经部署好的大模型服务，无需自己考虑基础设施（比如服务器、GPU 算力），特点：使用方便维护成本低，具有更完善的安全措施和合规保障。</p>
<h3 id="2、自部署"><a href="#2、自部署" class="headerlink" title="2、自部署"></a>2、自部署</h3><p>开发者在本地或者私有云部署开源大模型，特点是数据安全，无网络延迟。</p>
<p>本地使用开源项目 Ollama 快速安装大模型，<a class="link"   href="https://ollama.com/" >官方文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。对于 API 调用和各种应用程序的继承问题可以参考 <a class="link"   href="https://github.com/ollama/ollama/blob/main/docs/api.md" >Github 文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p>1）首先下载安装 Ollama，并安装其命令行工具：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768984538407.png"
                      alt="1768984538407"
                ></p>
<p>2）安装完成后，打开终端执行 <code>ollama --help</code> 可以查看用法；</p>
<p>3）进入到 <a class="link"   href="https://ollama.com/search" >Ollama 官网的模型广场 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中，挑选模型；</p>
<p>4）选中某个模型后，支持切换模型版本，建议刚开始选择小模型，安装速度更快，对硬件要求低（推荐 gemma3）；</p>
<p>5）执行 ollama 命令来快速安装并运行大模型，如 <code>ollama run gemma3:1b</code></p>
<p>6）安装完成后，即可在终端与大模型对话</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768984881973.png"
                      alt="1768984881973"
                ></p>
<h2 id="接入大模型的-3-种方式"><a href="#接入大模型的-3-种方式" class="headerlink" title="接入大模型的 3 种方式"></a>接入大模型的 3 种方式</h2><h3 id="1、AI-应用平台接入"><a href="#1、AI-应用平台接入" class="headerlink" title="1、AI 应用平台接入"></a>1、AI 应用平台接入</h3><p>国内比较著名且方便的平台有 <a class="link"   href="https://bailian.console.aliyun.com/" >阿里云百炼 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 和字节的 <a class="link"   href="https://www.volcengine.com/product/ark" >火山引擎 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。这种一站式的大模型开发及应用构建平台提供了从模型调用到应用构建的全流程支持。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768895132048.png"
                      alt="1768895132048"
                ></p>
<p>此外，还提供了知识库管理、应用评测、应用观测等功能，可以快速构建只能客服等应用。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768897394137.png"
                      alt="1768897394137"
                ></p>
<p>同时，针对阿里的产品还有一个 —— <a class="link"   href="https://cn.aliyun.com/product/dashscope?from_alibabacloud=" >模型服务灵积 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> （DashScope），是模型 API 接口，在底层开发时使用dashscope进行开发。</p>
<p>在使用平台的时候，可以创建智能体应用或者工作应用进行模型的使用，智能体应用的特点是可以预设 Prompt，然后再结合一些知识库检索等功能。而工作流应用是定义一个输入到输出的链式流程，可以更清晰的控制中间流程，提高逻辑性。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768898007203.png"
                      alt="1768898007203"
                ></p>
<h3 id="2、AI-软件客户端接入"><a href="#2、AI-软件客户端接入" class="headerlink" title="2、AI 软件客户端接入"></a>2、AI 软件客户端接入</h3><ol>
<li><a class="link"   href="https://www.cherry-ai.com/" >Cherry Studio <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>：一款集多模型对话、知识库管理、AI 绘画、翻译等功能于一体的全能 AI 助手平台。Cherry Studion 提供高度自定义的设计、强大的扩展能力和友好的用户体验。</li>
<li><a class="link"   href="https://cursor.com/cn" >Cursor <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>：以 AI 为核心的编程开发工具，可以快速生成项目代码、理解整个代码库并提供智能建议。</li>
</ol>
<h3 id="3、程序接入"><a href="#3、程序接入" class="headerlink" title="3、程序接入"></a>3、程序接入</h3><ol>
<li>直接调用 AI 大模型，比如调用 DeepSeek（更原生）</li>
<li>调用 AI 大模型平台创建的应用或者智能体（更方便）</li>
</ol>
<p>对于第一种方式，可以使用特定平台提供的 SDK 或者 API，参考平台的文档来接入；也可以使用 AI 开发框架，比如 Spring AI、Spring AI Alibaba、LangChain4j 等自主选择大模型进行调用，可以在 application.yml 中配置大模型而不修改代码。</p>
<div class="highlight-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">ai:</span></span><br><span class="line">    <span class="attr">dashscope:</span></span><br><span class="line">      <span class="attr">api-key:</span> <span class="string">$&#123;AI_DASHSCOPE_API_KEY&#125;</span></span><br><span class="line">      <span class="attr">chat:</span></span><br><span class="line">	<span class="attr">options:</span></span><br><span class="line">	<span class="attr">model:</span> <span class="string">deepseek-r1</span></span><br></pre></td></tr></table></figure></div>

<p>对于第二种方式，一般只能使用特定平台提供的 SDK 或者 API， 参考 <a class="link"   href="https://help.aliyun.com/zh/model-studio/spring-ai-alibaba-integrate-llm-application" >平台的文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 来接入，每个大模型服务平台的代码都不一样。</p>
<h2 id="程序调用-AI-大模型"><a href="#程序调用-AI-大模型" class="headerlink" title="程序调用 AI 大模型"></a>程序调用 AI 大模型</h2><p>在实际开发中，有多种方式可以在应用程序中调用 AI 大模型。</p>
<ol>
<li>SDK 接入：使用官方提供的软件开发工具包，最直接的集成方式；</li>
<li>HTTP 接入：通过 REST API 直接发送 HTTP 请求调用模型；</li>
<li>Spring AI：基于 Spring 生态系统的 AI 框架，更方便地接入大模型；</li>
<li>LangChain4j：专注于构建 LLM 应用的 Java 框架，提供丰富的 AI 调用组件。</li>
</ol>
<h3 id="1、SDK-接入"><a href="#1、SDK-接入" class="headerlink" title="1、SDK 接入"></a>1、SDK 接入</h3><p>SDK（Software Development Kit，软件开发工具包）是官方提供的最直接的集成方式，通常提供了完善的类型支持和错误处理机制。</p>
<p>1）首先需要按照官方文档安装 SDK：<a class="link"   href="https://help.aliyun.com/zh/model-studio/install-sdk" >安装 SDK 官方指南 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>在选择 SDK 版本时，建议在 Maven 仓库查看最新的版本号：<a class="link"   href="https://mvnrepository.com/artifact/com.alibaba/dashscope-sdk-java" >Maven 中央仓库版本信息 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>在 pom.xml 中引入依赖：</p>
<div class="highlight-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/com.alibaba/dashscope-sdk-java --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>dashscope-sdk-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.19.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>2）在大模型平台申请一个 API Key</p>
<p>3）项目中新建 demo.invoke 包，集中存放调用 AI 大模型的示例代码，<a class="link"   href="https://help.aliyun.com/zh/model-studio/qwen-api-reference#ab9194e9a55dk" >参考文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>为了安全管理 API 密钥，创建一个接口类来存储密钥信息（在实际生产环境中，使用应用配置文件或者环境变量，注意密钥不要上传到 git 仓库）：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">TestApiKey</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">String</span> <span class="variable">API_KEY</span> <span class="operator">=</span> <span class="string">&quot;你的 API Key&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>使用 SDK 调用模型的完整示例代码：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 建议dashscope SDK的版本 &gt;= 2.12.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.lang.System;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.aigc.generation.Generation;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.aigc.generation.GenerationParam;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.aigc.generation.GenerationResult;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.common.Message;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.common.Role;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.exception.ApiException;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.exception.InputRequiredException;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.exception.NoApiKeyException;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.dashscope.utils.JsonUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SdkAiInvoke</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> GenerationResult <span class="title function_">callWithMessage</span><span class="params">()</span> <span class="keyword">throws</span> ApiException, NoApiKeyException, InputRequiredException &#123;</span><br><span class="line">        <span class="type">Generation</span> <span class="variable">gen</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Generation</span>();</span><br><span class="line">        <span class="type">Message</span> <span class="variable">systemMsg</span> <span class="operator">=</span> Message.builder()</span><br><span class="line">                .role(Role.SYSTEM.getValue())</span><br><span class="line">                .content(<span class="string">&quot;You are a helpful assistant.&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="type">Message</span> <span class="variable">userMsg</span> <span class="operator">=</span> Message.builder()</span><br><span class="line">                .role(Role.USER.getValue())</span><br><span class="line">                .content(<span class="string">&quot;你是谁？&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="type">GenerationParam</span> <span class="variable">param</span> <span class="operator">=</span> GenerationParam.builder()</span><br><span class="line">                <span class="comment">// 若没有配置环境变量，请用百炼API Key将下行替换为：.apiKey(&quot;sk-xxx&quot;)</span></span><br><span class="line">                .apiKey(TestApiKey.API_KEY)</span><br><span class="line">                <span class="comment">// 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models</span></span><br><span class="line">                .model(<span class="string">&quot;qwen-plus&quot;</span>)</span><br><span class="line">                .messages(Arrays.asList(systemMsg, userMsg))</span><br><span class="line">                .resultFormat(GenerationParam.ResultFormat.MESSAGE)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="keyword">return</span> gen.call(param);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">GenerationResult</span> <span class="variable">result</span> <span class="operator">=</span> callWithMessage();</span><br><span class="line">            System.out.println(JsonUtils.toJson(result));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ApiException | NoApiKeyException | InputRequiredException e) &#123;</span><br><span class="line">            <span class="comment">// 使用日志框架记录异常信息</span></span><br><span class="line">            System.err.println(<span class="string">&quot;An error occurred while calling the generation service: &quot;</span> + e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        System.exit(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>4）运行项目，成功看到 AI 的回复：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768962173256.png"
                      alt="1768962173256"
                ></p>
<h3 id="2、HTTP-接入"><a href="#2、HTTP-接入" class="headerlink" title="2、HTTP 接入"></a>2、HTTP 接入</h3><p>对于 SDK 不支持的编程语言或需要更灵活控制的场景，可以直接使用 HTTP 请求调用 AI 大模型的 API。</p>
<p>优先级：SDK &gt; HTTP</p>
<p>HTTP 调用的详细说明可<a class="link"   href="https://help.aliyun.com/zh/model-studio/qwen-api-reference#b1320a1664b9a" >参考官方文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>：</p>
<div class="highlight-container" data-rel="Http"><figure class="iseeu highlight http"><table><tr><td class="code"><pre><span class="line">curl -X POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \</span><br><span class="line">-H &quot;Authorization: Bearer $DASHSCOPE_API_KEY&quot; \</span><br><span class="line">-H &quot;Content-Type: application/json&quot; \</span><br><span class="line">-d &#x27;&#123;</span><br><span class="line">    &quot;model&quot;: &quot;qwen-plus&quot;,</span><br><span class="line">    &quot;messages&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot;: &quot;system&quot;,</span><br><span class="line">            &quot;content&quot;: &quot;You are a helpful assistant.&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">            &quot;content&quot;: &quot;你是谁？&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure></div>

<p>测试代码：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HttpAiInvoke</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 替换为你的实际 API 密钥</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> <span class="string">&quot;https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置请求头</span></span><br><span class="line">        Map&lt;String, String&gt; headers = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        headers.put(<span class="string">&quot;Authorization&quot;</span>, <span class="string">&quot;Bearer &quot;</span> + TestApiKey.API_KEY);</span><br><span class="line">        headers.put(<span class="string">&quot;Content-Type&quot;</span>, <span class="string">&quot;application/json&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置请求体</span></span><br><span class="line">        <span class="type">JSONObject</span> <span class="variable">requestBody</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">        requestBody.put(<span class="string">&quot;model&quot;</span>, <span class="string">&quot;qwen-plus&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">JSONObject</span> <span class="variable">input</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">        JSONObject[] messages = <span class="keyword">new</span> <span class="title class_">JSONObject</span>[<span class="number">2</span>];</span><br><span class="line"></span><br><span class="line">        <span class="type">JSONObject</span> <span class="variable">systemMessage</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">        systemMessage.put(<span class="string">&quot;role&quot;</span>, <span class="string">&quot;system&quot;</span>);</span><br><span class="line">        systemMessage.put(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;You are a helpful assistant.&quot;</span>);</span><br><span class="line">        messages[<span class="number">0</span>] = systemMessage;</span><br><span class="line"></span><br><span class="line">        <span class="type">JSONObject</span> <span class="variable">userMessage</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">        userMessage.put(<span class="string">&quot;role&quot;</span>, <span class="string">&quot;user&quot;</span>);</span><br><span class="line">        userMessage.put(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;你是谁？&quot;</span>);</span><br><span class="line">        messages[<span class="number">1</span>] = userMessage;</span><br><span class="line"></span><br><span class="line">        input.put(<span class="string">&quot;messages&quot;</span>, messages);</span><br><span class="line">        requestBody.put(<span class="string">&quot;input&quot;</span>, input);</span><br><span class="line"></span><br><span class="line">        <span class="type">JSONObject</span> <span class="variable">parameters</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">        parameters.put(<span class="string">&quot;result_format&quot;</span>, <span class="string">&quot;message&quot;</span>);</span><br><span class="line">        requestBody.put(<span class="string">&quot;parameters&quot;</span>, parameters);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 发送请求</span></span><br><span class="line">        <span class="type">HttpResponse</span> <span class="variable">response</span> <span class="operator">=</span> HttpRequest.post(url)</span><br><span class="line">                .addHeaders(headers)</span><br><span class="line">                .body(requestBody.toString())</span><br><span class="line">                .execute();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 处理响应</span></span><br><span class="line">        <span class="keyword">if</span> (response.isOk()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;请求成功，响应内容：&quot;</span>);</span><br><span class="line">            System.out.println(response.body());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;请求失败，状态码：&quot;</span> + response.getStatus());</span><br><span class="line">            System.out.println(<span class="string">&quot;响应内容：&quot;</span> + response.body());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="3、Spring-AI"><a href="#3、Spring-AI" class="headerlink" title="3、Spring AI"></a>3、Spring AI</h3><p>Spring AI 是 Spring 生态系统的新成员，旨在简化 AI 功能与 Spring 应用的集成。</p>
<p>核心特性：</p>
<ol>
<li>跨 AI 供应商的可移植 API 支持，支持所有主流 AI 模型供应商，支持所有主流向量数据库</li>
<li>工具&#x2F;函数调用：允许模型请求执行客户端工具和函数，从而根据必要访问必要的实时信息并采取行动</li>
<li>可观测性：提供与 AI 相关操作的监控信息</li>
<li>文档 ETL 框架</li>
<li>AI 模型评估工具</li>
<li>ChatClient API（*）：与 AI 聊天模型通信的流式 API，用法类似于 WebClient 和 RestClient API</li>
<li>Advisors API（*）：封装常见的生成式 AI 模式，转换发送至语言模型（LLM）和从语言模型返回的数据，并提供跨各种模型和用例的可移植性。</li>
<li>结构化输出（*）：将 AI 模型输出映射到 POJO（普通 Java 对象）</li>
<li>支持聊天对话记忆和检索增强生成（RAG）。</li>
</ol>
<p><a class="link"   href="https://java2ai.com/docs/overview/" >参考文档Spring Ai Alibaba <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://java2ai.com/docs/1.0.0-M6.1/tutorials/chat-client/?spm=4347728f.1073474f.0.0.49347982Rt3eMR" >旧版（新版 Spring Ai Alibaba 不支持 ChatClient） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>1）引入依赖：</p>
<div class="highlight-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.cloud.ai<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-ai-alibaba-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0-M6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>2）编写配置：</p>
<div class="highlight-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">application:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">spring-ai-alibaba-qwq-chat-client-example</span></span><br><span class="line">  <span class="attr">ai:</span></span><br><span class="line">    <span class="attr">dashscope:</span></span><br><span class="line">      <span class="attr">api-key:</span> <span class="string">$&#123;AI_DASHSCOPE_API_KEY&#125;</span></span><br><span class="line">      <span class="attr">chat:</span></span><br><span class="line">        <span class="attr">options:</span></span><br><span class="line">          <span class="attr">model:</span> <span class="string">qwen-plus</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>3）编写示例代码，注意要注入 dashscopeChatModel：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 取消注释即可在 SpringBoot 项目启动时执行</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SpringAiAiInvoke</span> <span class="keyword">implements</span> <span class="title class_">CommandLineRunner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> ChatModel dashscopeChatModel;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">AssistantMessage</span> <span class="variable">output</span> <span class="operator">=</span> dashscopeChatModel.call(<span class="keyword">new</span> <span class="title class_">Prompt</span>(<span class="string">&quot;你好，我是鱼皮&quot;</span>))</span><br><span class="line">                .getResult()</span><br><span class="line">                .getOutput();</span><br><span class="line">        System.out.println(output.getText());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>上述代码实现了 CommandLineRunner 接口，在启动 Spring Boot 项目时，会自动注入大模型 ChatModel 依赖，并且单次执行该类的 run 方法达到测试效果。</p>
<p>（ChatModel 适合简单的对话场景，除了这种以外，Spring AI 还提供 ChatClient 调用方式，提供更多高级功能（比如会话记忆），适合复杂场景）</p>
<h3 id="4、LangChain4j"><a href="#4、LangChain4j" class="headerlink" title="4、LangChain4j"></a>4、LangChain4j</h3><p>和 Spring AI 作用一样，专注于构建基于 LLM 应用的 Java 框架，作为知名 AI 框架 LangChain 的 Java 版本，提供了丰富的工具和抽象层。LangChain 官方没有完全支持国内大模型 <a class="link"   href="https://docs.langchain4j.dev/integrations/language-models/" >官方文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，可参考 <a class="link"   href="https://github.com/langchain4j/langchain4j-community/tree/main/models" >社区版本的整合大模型包 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p>1）引入依赖：</p>
<div class="highlight-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/dev.langchain4j/langchain4j-community-dashscope --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>dev.langchain4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>langchain4j-community-dashscope<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0-beta2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>注意，LangChain4j 也提供了 Spring Boot Starter，方便在 Spring 项目中使用，最新版本号可以在 <a class="link"   href="https://mvnrepository.com/artifact/dev.langchain4j/langchain4j-community-dashscope" >Maven中央仓库 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 查询。由于此处已经引入了 Spring AI，防止冲突就不再引入。</p>
<p>2）参考 <a class="link"   href="https://docs.langchain4j.dev/get-started/" >LangChain 官方文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 来编写实例对话，创建一个 ChatModel 并调用。</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LangChainAiInvoke</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">ChatLanguageModel</span> <span class="variable">qwenModel</span> <span class="operator">=</span> QwenChatModel.builder()</span><br><span class="line">                .apiKey(TestApiKey.API_KEY)</span><br><span class="line">                .modelName(<span class="string">&quot;qwen-max&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="type">String</span> <span class="variable">answer</span> <span class="operator">=</span> qwenModel.chat(<span class="string">&quot;我是程序员鱼皮，这是编程导航 codefather.cn 的原创项目教程&quot;</span>);</span><br><span class="line">        System.out.println(answer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="5、Spring-AI-调用-Ollama-大模型"><a href="#5、Spring-AI-调用-Ollama-大模型" class="headerlink" title="5、Spring AI 调用 Ollama 大模型"></a>5、Spring AI 调用 Ollama 大模型</h3><p>1）首先，引入依赖：</p>
<div class="highlight-container" data-rel="Xml"><figure class="iseeu highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.ai<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-ai-ollama-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0-M6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>2）填写配置，注意模型为刚刚安装并可用的模型：</p>
<div class="highlight-container" data-rel="Yaml"><figure class="iseeu highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">ai:</span></span><br><span class="line">    <span class="attr">ollama:</span></span><br><span class="line">      <span class="attr">base-url:</span> <span class="string">http://localhost:11434</span></span><br><span class="line">      <span class="attr">chat:</span></span><br><span class="line">        <span class="attr">model:</span> <span class="string">gemma3:1b</span></span><br></pre></td></tr></table></figure></div>

<p>3）在 demo.invoke 包中编写一段测试代码：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 取消注释即可在 SpringBoot 项目启动时执行</span></span><br><span class="line"><span class="comment">//@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OllamaAiInvoke</span> <span class="keyword">implements</span> <span class="title class_">CommandLineRunner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> ChatModel ollamaChatModel;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">AssistantMessage</span> <span class="variable">output</span> <span class="operator">=</span> ollamaChatModel.call(<span class="keyword">new</span> <span class="title class_">Prompt</span>(<span class="string">&quot;你好，我是鱼皮&quot;</span>))</span><br><span class="line">                .getResult()</span><br><span class="line">                .getOutput();</span><br><span class="line">        System.out.println(output.getText());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="Prompt-工程"><a href="#Prompt-工程" class="headerlink" title="Prompt 工程"></a>Prompt 工程</h1><p>Prompt 工程又叫提示词工程，就是输入给 AI 的指令。提示词的质量直接影响到 AI 大模型输出的结果。在 AI 应用开发的时候，涉及到的技术有各种 Prompt 的优化，Advisor，对话记忆持久化，RAG 等多种技术。在我看来，<strong>这些技术的核心都是在根据用户的user prompt 进行各种优化来增强查询的效率和准确度</strong>，也可能会涉及到降低或者增加费用的情况。</p>
<h2 id="提示词分类"><a href="#提示词分类" class="headerlink" title="提示词分类"></a>提示词分类</h2><h3 id="核心-基于角色的分类"><a href="#核心-基于角色的分类" class="headerlink" title="核心 - 基于角色的分类"></a>核心 - 基于角色的分类</h3><p>在 AI 对话中，基于角色的分类是最常见的，通常存在 3 种主要类型的 Prompt：</p>
<p>1）User Prompt：用户向 AI 提供的实际问题、指令或信息，如</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">用户：帮我写一个使用 python 实现的 KMeans 代码</span><br></pre></td></tr></table></figure></div>

<p>2）System Prompt：设置 AI 模型行为规则和角色定位的隐藏指令，用户通常看不到，类似于系统给 AI 设定人格和能力边界</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">系统：你是一位经验丰富的恋爱顾问，擅长分析情感问题并提供建设性建议。请以温暖友善的语气回答用户的恋爱困惑，必要时主动询问更多信息以便提供更准确的建议。不要做出道德判断，而是尊重用户的情感体验并提供实用的沟通和相处技巧。回答时保持专业性，但避免使用过于学术的术语，确保普通用户能够理解你的建议。</span><br></pre></td></tr></table></figure></div>

<p>3）Assistant Prompt：在多轮对话种，之前的 AI 模型回复的话会作为上下文的一部分影响后续对话的理解和生成。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768987380425.png"
                      alt="1768987380425"
                ></p>
<h3 id="扩展知识-基于功能的分类"><a href="#扩展知识-基于功能的分类" class="headerlink" title="扩展知识 - 基于功能的分类"></a>扩展知识 - 基于功能的分类</h3><p>1、指令型提示词（明确任务）</p>
<p>2、对话型提示词（自然对话）</p>
<p>3、创意型提示词（引导创作故事）</p>
<p>4、角色扮演型提示词（类似用户预设 System Prompt）</p>
<p>5、少样本学习提示词：提供一些示例，引导 AI 理解所需的输出格式和风格。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">将以下句子改写为正式商务语言：</span><br><span class="line">示例1：</span><br><span class="line">原句：这个想法不错。</span><br><span class="line">改写：该提案展现了相当的潜力和创新性。</span><br><span class="line"></span><br><span class="line">示例2：</span><br><span class="line">原句：我们明天见。</span><br><span class="line">改写：期待明日与您会面，继续我们的商务讨论。</span><br><span class="line"></span><br><span class="line">现在请改写：这个价格太高了。</span><br></pre></td></tr></table></figure></div>

<h3 id="扩展知识-基于复杂度的分类"><a href="#扩展知识-基于复杂度的分类" class="headerlink" title="扩展知识 - 基于复杂度的分类"></a>扩展知识 - 基于复杂度的分类</h3><p>1、简单提示词</p>
<p>2、复合提示词</p>
<p>3、链式提示词（一系列连续的、相互依赖的提示词，有一点工作流应用的意味）</p>
<p>4、模板提示词（包含可替换变量的标准化提示词结构，常用于大规模应用）</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">你是一位专业的&#123;领域&#125;专家。请回答以下关于&#123;主题&#125;的问题：&#123;具体问题&#125;。</span><br><span class="line">回答应包含&#123;要点数量&#125;个关键点，并使用&#123;风格&#125;的语言风格。</span><br></pre></td></tr></table></figure></div>

<h2 id="Token"><a href="#Token" class="headerlink" title="Token"></a>Token</h2><p>不同模型对 Token 的计算规则不一样，也并非完全按照汉字或者字母个数去划定，需要估算或使用<a class="link"   href="https://tiktoken.aigc2d.com/" >计算工具 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<h3 id="Token-成本优化技巧"><a href="#Token-成本优化技巧" class="headerlink" title="Token 成本优化技巧"></a>Token 成本优化技巧</h3><p>1、精简系统提示词</p>
<p>2、定期清理对话历史</p>
<p>3、使用向量检索代替直接输入（RAG）</p>
<p>4、结构化替代自然语言</p>
<p>优化前：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">请问如何制作披萨？首先需要准备面粉、酵母、水、盐、橄榄油作为基础面团材料。然后根据口味选择酱料，可以是番茄酱或白酱。接着准备奶酪，最常用的是马苏里拉奶酪。最后准备各种配料如意大利香肠、蘑菇、青椒等。</span><br></pre></td></tr></table></figure></div>

<p>优化后：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">披萨制作材料：</span><br><span class="line">- 面团：面粉、酵母、水、盐、橄榄油</span><br><span class="line">- 酱料：番茄酱/白酱</span><br><span class="line">- 奶酪：马苏里拉</span><br><span class="line">- 配料：意大利香肠、蘑菇、青椒等</span><br><span class="line"></span><br><span class="line">如何制作？</span><br></pre></td></tr></table></figure></div>

<h2 id="Prompt-优化技巧"><a href="#Prompt-优化技巧" class="headerlink" title="Prompt 优化技巧"></a>Prompt 优化技巧</h2><h3 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h3><h4 id="1、Prompt-学习"><a href="#1、Prompt-学习" class="headerlink" title="1、Prompt 学习"></a>1、Prompt 学习</h4><ul>
<li><a class="link"   href="https://www.promptingguide.ai/zh" >Prompt Engineering Guide 提示词工程指南 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://platform.openai.com/docs/guides/prompt-engineering" >OpenAI 提示词工程指南 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://docs.spring.io/spring-ai/reference/api/prompt.html#_prompt_engineering" >Spring AI 提示词工程指南 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://claude.com/app-unavailable-in-region" >Authropic 提示词工程指南 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://github.com/anthropics/prompt-eng-interactive-tutorial" >Authropic 提示词工程指南（开源仓库） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://open.bigmodel.cn/dev/guidelines/LanguageModels" >智谱 AI Prompt 设计指南 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<h4 id="2、Prompt-提示词库"><a href="#2、Prompt-提示词库" class="headerlink" title="2、Prompt 提示词库"></a>2、Prompt 提示词库</h4><ul>
<li>文本对话：<a class="link"   href="https://claude.com/app-unavailable-in-region" >Authropic 提示词库 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li>AI 绘画：<a class="link"   href="https://promptlibrary.org/" >Midjourney 提示词库 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<h3 id="基础提示技巧"><a href="#基础提示技巧" class="headerlink" title="基础提示技巧"></a>基础提示技巧</h3><p>1、明确指定任务和角色（写好 System Prompt）</p>
<p>2、提供详细说明和具体实例（提供足够的上下文和期望输出格式示例）、</p>
<p>3、使用结构化格式引导思维</p>
<p>4、明确输出格式要求</p>
<h3 id="进阶提示技巧"><a href="#进阶提示技巧" class="headerlink" title="进阶提示技巧"></a>进阶提示技巧</h3><p>1、思维链提示法</p>
<p>2、少样本学习</p>
<p>3、分步骤指导</p>
<p>4、自我评估和修正</p>
<p>5、知识检索和引用</p>
<p>6、多视角分析</p>
<p>7、多模态思维</p>
<h3 id="提示词调试与优化"><a href="#提示词调试与优化" class="headerlink" title="提示词调试与优化"></a>提示词调试与优化</h3><p>1、迭代式提示优化</p>
<p>2、边界测试</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">尝试解决以下具有挑战性的数学问题:</span><br><span class="line">证明在三角形中，三条高的交点、三条中线的交点和三条角平分线的交点在同一条直线上。</span><br><span class="line"></span><br><span class="line">如果你发现难以直接证明:</span><br><span class="line">1. 说明你遇到的具体困难</span><br><span class="line">2. 考虑是否有更简单的方法或特例可以探讨</span><br><span class="line">3. 提供一个思路框架，即使无法给出完整证明</span><br></pre></td></tr></table></figure></div>

<p>3、提示词模板化</p>
<p>4、错误分析与修正</p>
<h1 id="AI-应用方案设计"><a href="#AI-应用方案设计" class="headerlink" title="AI 应用方案设计"></a>AI 应用方案设计</h1><p>AI 应用方案设计的 2 个核心：</p>
<ul>
<li>系统提示词的设计</li>
<li>多轮对话的实现</li>
</ul>
<h2 id="1、系统提示词设计"><a href="#1、系统提示词设计" class="headerlink" title="1、系统提示词设计"></a>1、系统提示词设计</h2><p>巧思：让 AI 帮助优化系统提示词</p>
<h2 id="2、多轮对话实现"><a href="#2、多轮对话实现" class="headerlink" title="2、多轮对话实现"></a>2、多轮对话实现</h2><p>要实现具有“记忆力”的 AI 应用，让 AI 能够记住用户之前的对话内容并保持上下文连贯性，可以使用 Spring AI 框架的 <strong>对话记忆能力</strong>。</p>
<h3 id="ChatClient-特性"><a href="#ChatClient-特性" class="headerlink" title="ChatClient 特性"></a>ChatClient 特性</h3><p>相较于 ChatModel，ChatClient 支持更复杂灵活的链式调用（Fluent API）:</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 基础用法</span></span><br><span class="line"><span class="type">ChatResponse</span> <span class="variable">response</span> <span class="operator">=</span> chatModel.call(<span class="keyword">new</span> <span class="title class_">Prompt</span>(<span class="string">&quot;你好&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 高级用法</span></span><br><span class="line"><span class="type">ChatClient</span> <span class="variable">chatClient</span> <span class="operator">=</span> ChatClient.builder(chatModel)</span><br><span class="line">	.defaultSystem(<span class="string">&quot;你是恋爱顾问&quot;</span>)</span><br><span class="line">	.build();</span><br><span class="line"></span><br><span class="line"><span class="type">String</span> <span class="variable">response</span> <span class="operator">=</span> chatClient.prompt().user(<span class="string">&quot;你好&quot;</span>).call().content();</span><br></pre></td></tr></table></figure></div>

<p>Spring AI 提供了多种构建 ChatClient 的方式，比如自动注入、通过建造者模式手动构造：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 方式1：使用构造器注入</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ChatService</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ChatClient chatClient;</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ChatService</span><span class="params">(ChatClient.Builder builder)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.chatClient = builder</span><br><span class="line">            .defaultSystem(<span class="string">&quot;你是恋爱顾问&quot;</span>)</span><br><span class="line">            .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方式2：使用建造者模式</span></span><br><span class="line"><span class="type">ChatClient</span> <span class="variable">chatClient</span> <span class="operator">=</span> ChatClient.builder(chatModel)</span><br><span class="line">    .defaultSystem(<span class="string">&quot;你是恋爱顾问&quot;</span>)</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></div>

<p>ChatClient 支持多种响应格式，比如返回 ChatResponse 对象，返回实体对象、流式返回：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ChatClient支持多种响应格式</span></span><br><span class="line"><span class="comment">// 1. 返回 ChatResponse 对象（包含元数据如 token 使用量）</span></span><br><span class="line"><span class="type">ChatResponse</span> <span class="variable">chatResponse</span> <span class="operator">=</span> chatClient.prompt()</span><br><span class="line">    .user(<span class="string">&quot;Tell me a joke&quot;</span>)</span><br><span class="line">    .call()</span><br><span class="line">    .chatResponse();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 返回实体对象（自动将 AI 输出映射为 Java 对象）</span></span><br><span class="line"><span class="comment">// 2.1 返回单个实体</span></span><br><span class="line"><span class="keyword">record</span> <span class="title class_">ActorFilms</span><span class="params">(String actor, List&lt;String&gt; movies)</span> &#123;&#125;</span><br><span class="line"><span class="type">ActorFilms</span> <span class="variable">actorFilms</span> <span class="operator">=</span> chatClient.prompt()</span><br><span class="line">    .user(<span class="string">&quot;Generate the filmography for a random actor.&quot;</span>)</span><br><span class="line">    .call()</span><br><span class="line">    .entity(ActorFilms.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.2 返回泛型集合</span></span><br><span class="line">List&lt;ActorFilms&gt; multipleActors = chatClient.prompt()</span><br><span class="line">    .user(<span class="string">&quot;Generate filmography for Tom Hanks and Bill Murray.&quot;</span>)</span><br><span class="line">    .call()</span><br><span class="line">    .entity(<span class="keyword">new</span> <span class="title class_">ParameterizedTypeReference</span>&lt;List&lt;ActorFilms&gt;&gt;() &#123;&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 流式返回（适用于打字机效果）</span></span><br><span class="line">Flux&lt;String&gt; streamResponse = chatClient.prompt()</span><br><span class="line">    .user(<span class="string">&quot;Tell me a story&quot;</span>)</span><br><span class="line">    .stream()</span><br><span class="line">    .content();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 也可以流式返回ChatResponse</span></span><br><span class="line">Flux&lt;ChatResponse&gt; streamWithMetadata = chatClient.prompt()</span><br><span class="line">    .user(<span class="string">&quot;Tell me a story&quot;</span>)</span><br><span class="line">    .stream()</span><br><span class="line">    .chatResponse();</span><br></pre></td></tr></table></figure></div>

<p>可以给 ChatClient 设置默认参数，比如系统提示词，还可以在对话时动态更改系统提示词的变量，类似模板的概念：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义默认系统提示词</span></span><br><span class="line"><span class="type">ChatClient</span> <span class="variable">chatClient</span> <span class="operator">=</span> ChatClient.builder(chatModel)</span><br><span class="line">        .defaultSystem(<span class="string">&quot;You are a friendly chat bot that answers question in the voice of a &#123;voice&#125;&quot;</span>)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对话时动态更改系统提示词的变量</span></span><br><span class="line">chatClient.prompt()</span><br><span class="line">        .system(sp -&gt; sp.param(<span class="string">&quot;voice&quot;</span>, voice))</span><br><span class="line">        .user(message)</span><br><span class="line">        .call()</span><br><span class="line">        .content());</span><br></pre></td></tr></table></figure></div>

<p>此外，还支持指定默认对话选项、默认拦截器、默认函数调用等等。</p>
<h3 id="Advisors"><a href="#Advisors" class="headerlink" title="Advisors"></a>Advisors</h3><p>Spring AI 使用 <a class="link"   href="https://docs.spring.io/spring-ai/reference/api/advisors.html" >Advisors <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 机制来增强 AI 的能力，在调用 AI 前和调用 AI 后可以执行一些额外的操作，比如：</p>
<ul>
<li>前置增强：调用 AI 前改写 Prompt 提示词、检查一下提示词是否安全</li>
<li>后置增强：调用 AI 后记录一下日志、处理一下返回结果</li>
</ul>
<p>用法很简单（鱼皮类比为拦截器），可以直接为 ChatClient 指定默认拦截器，比如对话记忆拦截器 MessageChatMemoryAdvisor 可以帮助我们实现多轮对话能力，省去自己维护对话列表的麻烦。</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">var</span> <span class="variable">chatClient</span> <span class="operator">=</span> ChatClient.builder(chatModel)</span><br><span class="line">    .defaultAdvisors(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">MessageChatMemoryAdvisor</span>(chatMemory), <span class="comment">// 对话记忆 advisor</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">QuestionAnswerAdvisor</span>(vectorStore)    <span class="comment">// RAG 检索增强 advisor</span></span><br><span class="line">    )</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line"><span class="type">String</span> <span class="variable">response</span> <span class="operator">=</span> <span class="built_in">this</span>.chatClient.prompt()</span><br><span class="line">    <span class="comment">// 对话时动态设定拦截器参数，比如指定对话记忆的 id 和长度</span></span><br><span class="line">    .advisors(advisor -&gt; advisor.param(<span class="string">&quot;chat_memory_conversation_id&quot;</span>, <span class="string">&quot;678&quot;</span>)</span><br><span class="line">            .param(<span class="string">&quot;chat_memory_response_size&quot;</span>, <span class="number">100</span>))</span><br><span class="line">    .user(userText)</span><br><span class="line">    .call()</span><br><span class="line">	.content();</span><br></pre></td></tr></table></figure></div>

<p>Advisors 的原理如下：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1768994593838.png"
                      alt="1768994593838"
                ></p>
<p>原理解释：</p>
<ol>
<li>Spring AI 框架从用户的 Prompt 创建一个 AdvisedRequest，同时创建一个空的 AdvisorContext 对象，用于传递信息；</li>
<li>链中每个 advisor 处理这个请求，可能对其进行修改。或者，可以选择不调用下一个实体来阻止请求继续传递，这时该 advisor 负责 填充响应内容；</li>
<li>由框架提供的最终 advisor 将请求发送给聊天模型 ChatModel；</li>
<li>聊天模型的响应随后通过 advisor 链传回，并被转换为 AdvisedResponse。后者包含了共享的 AdvisorContext 实例；</li>
<li>每个 advisor 都可以处理或者修改这个响应；</li>
<li>最终的 AdvisedResponse 通过提取 ChatCompletion 返回给客户端。</li>
</ol>
<p>实际开发中，可以使用多个 advisor，组合在一起相当于一条拦截器链条。每个拦截器是有顺序的，通过 <code>getOrder()</code> 方法获取到顺序，值越低优先级越高。如下面代码并不是按照写入的顺序决定，而是根据 <code>getOrder()</code> 决定。</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">var</span> <span class="variable">chatClient</span> <span class="operator">=</span> ChatClient.builder(chatModel)</span><br><span class="line">    .defaultAdvisors(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">MessageChatMemoryAdvisor</span>(chatMemory), <span class="comment">// 对话记忆 advisor</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">QuestionAnswerAdvisor</span>(vectorStore)    <span class="comment">// RAG 检索增强 advisor</span></span><br><span class="line">    )</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></div>

<p>Advisor 类图如下：<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1769044018902.png"
                      alt="1769044018902"
                ></p>
<p>从上图中可以发现，Advisors 分为 2 种模式：Streaming 和 Non-Streaming，二者在用法上没有明显区别但是在返回值上有所不同。当需要自主实现 Advisors 时，需要保证实现两种方法。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/AI-%E5%BC%80%E5%8F%91%E6%8A%80%E6%B3%95/1769044961293.png"
                      alt="1769044961293"
                ></p>
]]></content>
      <tags>
        <tag>AI、JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning:base &amp; advance</title>
    <url>/2025/06/11/Machine-Learning-base-advance/</url>
    <content><![CDATA[<p>机器学习常用于数据预处理、数据分析和数据挖掘之中。在今天主流的观念中，机器学习会被分为传统机器学习和深度学习两种，传统机器学习具有更好的可解释性，如针对回归问题的线性回归、针对分类问题的逻辑回归，树（KNN），支持向量机（SVM），还有一些聚类算法如K-Means，PCA，层次聚类（Hierarchical Clustering），关联规则等。而对于深度学习问题，则是基于很多层构建的如MLP，CNN（卷积层, Yolo），RNN（LSTM），Transformer(decoder, encoder, Bert, Chatgpt…)。</p>
<p>在这篇文章中，重点记录和整理我对于机器学习的理解，以构建自己的知识网络。我分为Base和Advance两个部分，base部分讲解基础，Advance部分记录一些机器学习更高级的应用如Ensemble等。</p>
<h2 id="Base">Base</h2>
<p>在学习传统机器学习的时候，第一个概念是supervised learning、unsupervised learning和unsupervised learning，即监督学习、非监督学习和半监督学习。评判的标准是是否有标签（label），有标签就是supervised learning（用各项指标预测癌症，癌症是标签，各项指标是data，常用于预测或者分类），无标签（没有预定的答案，如可以用DBSCAN去发现社群关系，用PCA去降低数据维度，常用于预处理任务），还有半监督学习（强调利用少量标注数据+大量未标注数据进行训练，是一种针对成本节约而诞生的问题）</p>
<p>同时，对于数据类型问题，常会面对两种数据类型，连续性数据如房屋面积、离散性数据如地理位置。对于连续性数据，常用的预处理方法是归一化（normalization/standardization），具体有Min-max Scaling，Z-Score standarlization，Robust Scaling、Log Transform，Quanruke Normalization；而对于离散型数据，最著名的方法是One-hot Encoding（独热编码），除此以外还有序号编码（Ordinary Encoding），目标编码（Target Encoding）。</p>
<h3 id="Regression">Regression</h3>
<p>回归问题的应用是基于一些特征（data）去预测一个实例的具体数值（label），如可以基于周边的配套设施，房屋面积，地理位置信息等去预测房价。</p>
<p>在思考回归问题的时候，有一种思考方式是基于矩阵的角度思考然后直接通过矩阵运算得到系数，另外一种是最小二乘法去不断求解，是一种简单优化问题，即最小化Loss。</p>
<h4 id="Linear-regression">Linear regression</h4>
<h4 id="Lasso">Lasso</h4>
<h4 id="Ridge">Ridge</h4>
<h4 id="Elastic-Net">Elastic - Net</h4>
<h3 id="Classification">Classification</h3>
<h2 id="Advance">Advance</h2>
]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL事务隔离</title>
    <url>/2025/06/06/MySQL%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/</url>
    <content><![CDATA[<h1>事务</h1>
<h2 id="事务的定义">事务的定义</h2>
<p>事务是指作为单个逻辑工作单元执行的一系列操作，这些操作要么全部执行成功，要么全部不执行，保证数据库从一个一致的状态转变为另一个一致状态。核心目的：保证并发程序的顺利执行。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 开始事务</span><br><span class="line">START TRANSACTION;  -- 或者 BEGIN</span><br><span class="line"></span><br><span class="line">-- 执行SQL语句</span><br><span class="line">INSERT INTO accounts (user_id, balance) VALUES (1, 1000);</span><br><span class="line">UPDATE accounts SET balance = balance - 100 WHERE user_id = 1;</span><br><span class="line">UPDATE accounts SET balance = balance + 100 WHERE user_id = 2;</span><br><span class="line"></span><br><span class="line">-- 提交事务</span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">-- 或者回滚事务</span><br><span class="line">ROLLBACK;</span><br></pre></td></tr></table></figure></div>
<h2 id="事务的基本特性-ACID">事务的基本特性 ACID</h2>
<ul>
<li>A 原子性：保证事务中的所有操作要么全部执行，要么全部不执行；</li>
<li>C 一致性：事务执行前后，数据库从一个一致状态转换为另一个一致状态；</li>
<li>I 隔离性：多个事务并发执行的时候，事务之间互不影响；</li>
<li>D 持久性：事务一旦提交，结果是永久的。</li>
</ul>
<p>有一种角度思考事务的基本特性，就是通过事务的原子性，隔离性和持久性去实现事务的一致性。</p>
<h2 id="事务的隔离性">事务的隔离性</h2>
<p>在涉及到事务的隔离性上时，首先要明白为什么需要隔离性。因为当多个事务并发执行的时候，容易出现以下问题：</p>
<ul>
<li>脏读：指一个事务可以读到其他事务未提交的修改（修改问题）；</li>
<li>不可重复读：指一个事务重复读同一个记录时，前后内容不一致（修改问题）；</li>
<li>幻读：指一个事务重复读同一个记录时，前后数量不一致（插入问题）；</li>
</ul>
<h2 id="事务隔离级别的具体定义">事务隔离级别的具体定义</h2>
<p>事务的隔离级别由低到高为：读未提交，读已提交，可重复读，串行化。随着事务的隔离级别越来越高，事务的执行效率也越来越低。</p>
<ul>
<li>读未提交：一个事务可以读取另一个事务未提交的修改；</li>
<li>读已提交：一个事务可以读取另一个事务已提交的修改；</li>
<li>可重复读：一个事务执行过程中看到的数据总是和启动时的数据保持一致；</li>
<li>串行化：对于同一行记录，读会加读锁，写会加写锁。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完才能开始执行。
<ul>
<li>串行化下锁的具体规则
<ul>
<li>读锁（共享锁/S锁）与写锁（排他锁/X锁）会冲突</li>
<li>读锁与读锁不会冲突</li>
<li>写锁与写锁会冲突</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="事务的具体实现">事务的具体实现</h2>
<p>首先，事务的具体实现依靠的是执行引擎InnoDB，它实现了多种锁和MVCC来应对并发问题时的事务隔离性问题。</p>
<h3 id="MVCC">MVCC</h3>
<p>在事务的可重复读的隔离条件下，由数据库的多版本并发控制（MVCC）来支持。MVCC类似于一种视图概念，是在事务启动的时候针对整个库的一种快照。InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。</p>
<p>按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。<br>
因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。（根据undo log回滚）</p>
<p>InnoDB为每个事务在启动的时候构建了一个数组，用来保存这个事务在启动瞬间，当前正在“活跃”的所有事务ID。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。<br>
这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</p>
<p>InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</p>
<h1>锁</h1>
<p>MySQL里的锁大致可以分为全局锁、表锁和行锁。</p>
<h2 id="全局锁">全局锁</h2>
<p>全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p>
<p><strong>应用场景</strong>：全库逻辑备份（通过FTWRL来确保数据库不会被其他线程修改，此时的数据库是只读的状态）</p>
<p>全库逻辑备份的方法二：在可重复读隔离级别下开启一个事务（拿到一致性视图，MVCC）-（mysqldump官方自带的逻辑备份工具，使用参数-single-transaction）。</p>
<p>全库逻辑备份的方法三：将数据库设置为readonly（不过不建议这样做，因为通常会依赖数据库是否是readonly来判断是主库还是备库，同时应对异常处理机制上也有差异，FTWRL会在异常后恢复，但是readonly会保持只读状态）</p>
<h2 id="表级锁">表级锁</h2>
<p>MySQL里面表级锁有两种：一种是表锁，另一种是MDL（meta data lock）。</p>
<ul>
<li>表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。</li>
<li>另一类表级的锁是 MDL（metadata lock)。<strong>MDL 不需要显式使用，在访问一个表的时候会被自动加上</strong>。MDL 的作用是，保证读写的正确性。<strong>MDL作用是防止DDL(data definition language)和DML(data manipulation language)并发的冲突</strong>
<ul>
<li>MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
<ul>
<li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li>
<li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="行锁">行锁</h2>
<p>InnoDB支持行锁但是MyISAM不支持行锁。</p>
<h3 id="两阶段锁">两阶段锁</h3>
<p>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束的时候才释放。</p>
<p>（优化思路：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放）。</p>
<h3 id="死锁和死锁检测">死锁和死锁检测</h3>
<p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。</p>
<p>当发生死锁的时候，会有两种策略：</p>
<ul>
<li>一种策略是，直接进入等待，直到超时。通过参数innodb_lock_wait_timeout来设置；</li>
<li>另一种策略是，发起死锁检测，当检测到死锁的时候，回滚某一个事务并让其他事务继续执行。通过参数innodb_deadlock_detect设置为on启动。（常用，优化思路-&gt;控制并发度）</li>
</ul>
<h2 id="间隙锁">间隙锁</h2>
<p>如果只有行锁的话，两个事务在并发执行的时候，事务A在重复读取一个数据的时候，如果事务B插入了一个数据，事务A有可能会读取到这个新的数据上去。而这就是幻读问题，既一个事务在重复读取同一个条件的时候，两次读取的结果数是不同的。</p>
<p>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读是在“当前读”下才会出现的（select for update：当前读，对数据加写锁；select share in mode：当前读，对数据加读锁）</p>
<h1>开发架构</h1>
<p>我认为在思考并发问题的时候，事务的设计和锁的实现保障了在本地的MySQL数据库能合理解各种决并发问题。不过，为了应对更大的需求量，会有主从架构的出现来缓解访问压力，我认为这里也需要考虑主备的一致性问题，所以把它算在了并发问题的第三部分。</p>
<h2 id="一主一备">一主一备</h2>
<h3 id="MySQL主备的基本原理">MySQL主备的基本原理</h3>
<p>客户端的读写都直接访问节点A，而节点B作为节点A的备库，只是将A的更新都同步过来，到本地执行。</p>
<p>一般会把节点B设置为只读模式（readonly），原因如下：（同步更新的线程拥有超级权限可以无视readonly）</p>
<ol>
<li>有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；</li>
<li>防止切换过程，因为双写产生bug；</li>
<li>可以用readonly去判断是否为备库。</li>
</ol>
<p>备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：</p>
<ol>
<li>在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。</li>
<li>在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接，sql_thread负责在本地执行binlog上的更新语句。</li>
<li>主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。</li>
<li>备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。</li>
<li>sql_thread 读取中转日志，解析出日志里的命令，并执行。</li>
</ol>
<h3 id="双M结构">双M结构</h3>
<p>上述是M-S结构，实际工作中更常用的是双M结构，区别在于双M结构的节点A和节点B互为主备关系。这样在切换的时候不需要再修改主备关系。</p>
<p>问题：因为互为备库，所以会出现循环复制的问题，以下是解决方案：</p>
<ul>
<li>规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；</li>
<li>一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；</li>
<li>每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。</li>
</ul>
<p>按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：</p>
<ul>
<li>从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；</li>
<li>传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；</li>
<li>再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。</li>
</ul>
<h2 id="一主多从">一主多从</h2>
]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL基础架构</title>
    <url>/2025/05/30/MySQL%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<p>本篇文章重点讲解MySQL的基础架构问题，同时会说明在MySQL问题上一般需要重点关注的问题。</p>
<p>了解MySQL的基础架构可以从一条MySQL语句的执行顺序去学习。MySQL大体可以分为Server层和引擎层。Server层包括连接器、缓存、分析器、优化器、执行器。存储引擎层提供数据库的读写接口，是插件式架构，最常用的是InnoDB，除此之外还有MyISAM，Memory。</p>
<h2 id="Server层">Server层</h2>
<p>Server层涵盖了MySQL大多数的核心服务功能以及所有的内置函数（如时间、日期、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p>
<h3 id="连接器">连接器</h3>
<p><strong>管理连接，权限验证</strong>。</p>
<p>连接&amp;长连接&amp;短连接</p>
<p>连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。先连接，再在权限表中检查权限。如果连接之后没有后续动作就会处于空闲状态，使用 show processlist可以查看，sleep表示这个连接处于空闲状态。客户端如果长时间没有动静，连接器就会自动断开，这个时间是由wait_timeout控制的，默认值是8个小时。</p>
<p>数据库连接分为长连接和短连接两种，长连接指一次连接成功后，如果客户端持续请求则一直使用一个连接。短连接指的是每次连接完成很短的几次查询后就断开。不过MySQL在使用长连接的时候会面临一个问题，MySQL在使用过程的时候临时内存保存在连接对象上，这些资源在连接断开才会释放。长连接容易因为内存过大被操作系统强行杀掉。</p>
<p>解决措施：定期断开长连接；MySQL5.7之后，可以通过mysql_reset_connection重新初始化同时不用重新连接。</p>
<h3 id="查询缓存">查询缓存</h3>
<p><strong>命中则直接返回结果</strong>。</p>
<p>select语句优化</p>
<p>之前执行的语句和结果可能以key-value存储在内存上。如果发现当前执行的语句之前执行过，可以通过缓存返回。不过不建议使用，因为查询失败率很高，只要有一个表更新则缓存就会被清空。同时，在MySQL8.0之后删除了这个功能。</p>
<h3 id="分析器">分析器</h3>
<p><strong>词法分析，语法分析</strong>。</p>
<p>没有命中查询缓存，则开始真正执行语句。先做词法分析，再做语法分析。</p>
<h3 id="优化器">优化器</h3>
<p><strong>执行计划生成，索引选择</strong>。</p>
<p>索引</p>
<p>当有多个索引的时候，优化器来决定选择哪个索引；当有多个表的时候，优化器来决定先使用哪个表。当优化器完成优化的时候，这个语句的执行方案就已经完成了。</p>
<h3 id="执行器">执行器</h3>
<p><strong>操作引擎，返回结果</strong>。</p>
<p>权限验证</p>
<p>开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。</p>
<p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</p>
<h2 id="引擎层">引擎层</h2>
<p>不同的引擎对于表数据的取数方法不同，对于事物和锁的支持也不同。</p>
<h3 id="InnoDB">InnoDB</h3>
<p>对事务的支持，redo log的实现，行锁的实现。</p>
<h3 id="MyISAM">MyISAM</h3>
<h3 id="Memory">Memory</h3>
<h2 id="问题综述">问题综述</h2>
<h3 id="权限验证">权限验证</h3>
<ol>
<li>连接器会鉴权用户是否具有连接 MySQL 实例的权限，包括用户的账号和密码是否正确，以及用户是否被授予连接权限。</li>
<li>分析器会鉴权用户是否具有对所请求的数据库和表的查询权限，包括是否具有查询、插入、更新、删除等操作的权限，以及是否具有访问某些列的权限。</li>
<li>执行器会鉴权用户是否具有执行所请求的操作的权限，包括对表的读、写等操作权限，以及是否具有执行存储过程和触发器的权限。</li>
</ol>
]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL索引优化</title>
    <url>/2025/06/06/MySQL%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="索引作用">索引作用</h2>
<p>索引的出现是为了提高数据查询的效率，如同书的目录一样。</p>
<h2 id="索引模型">索引模型</h2>
<p>常见的索引模型有哈希表，有序数组和搜索树（B+树）。</p>
<p>InnoDB的索引由B+树实现，其中主键树的叶子节点为数据，非叶子节点为主键的具体值。普通索引的叶子节点是具体的主键值。同时，InnoDB的自适应哈希索引（InnoDB hash index）对频繁访问的索引页自动在内存中建立哈希索引。</p>
<p>特点：B+树是多路平衡查找树，适合磁盘存储。支持等值查询，同时叶子节点通过指针连接，支持高效的范围查询。</p>
<p>Memory的索引实现由哈希表实现。</p>
<h2 id="覆盖索引">覆盖索引</h2>
<h3 id="最左前缀原则">最左前缀原则</h3>
<h3 id="索引下推">索引下推</h3>
<h2 id="常见问题">常见问题</h2>
<h3 id="唯一性索引和普通索引的选择（change-buffer的优化机制）">唯一性索引和普通索引的选择（change buffer的优化机制）</h3>
<h3 id="索引选错问题（优化层的工作原理）">索引选错问题（优化层的工作原理）</h3>
]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL日志系统</title>
    <url>/2025/05/30/MySQL%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>日志系统是为了从各种意外中恢复而诞生的机制，在之后发展的时候又延申了许多功能。在MySQL中，最先被发明的是在Server层的binlog（用于主从复制和数据恢复），之后InnoDB实现了Redo Log（防止崩溃）和undo log（支持事务）。除此以外，还有error log（记录MySQL服务器启动、运行或停止时出现的错误信息），general query log（记录所有到达MySQL服务器的语句），slow query log（记录执行时间超过 <code>long_query_time</code>的查询，用于性能分析和优化），Relay log（主从复制中，从服务器保存主服务器binlog的中间日志），等等。本篇文章先重点介绍binlog, redo log和undo log之后再延展一些相关的使用。</p>
<h2 id="Redo-Log">Redo Log</h2>
<p>特点：WAL ( Write-Ahead Logging )</p>
<p>功能：crash-safe(即使异常重启，之前提交的记录也不会丢)</p>
<p>层次：引擎层</p>
<p>具体实现：</p>
<ol>
<li>更新的时候，基于WAL机制，先写日志，再更新内存，等空闲的时候再去写磁盘。</li>
<li>InnoDB特有</li>
<li>InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写</li>
<li>write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos 和 checkpoint 之间的是log上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示log满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。</li>
</ol>
<h2 id="Bin-Log">Bin Log</h2>
<p>功能：</p>
<p>层次：Server层</p>
<p>具体实现：</p>
<h2 id="Undo-Log">Undo Log</h2>
<p>功能：</p>
<p>层次：</p>
<p>具体实现：</p>
]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG 知识库</title>
    <url>/2026/01/22/RAG-%E7%9F%A5%E8%AF%86%E5%BA%93/</url>
    <content><![CDATA[<h1 id="RAG-知识库基本概念"><a href="#RAG-知识库基本概念" class="headerlink" title="RAG 知识库基本概念"></a>RAG 知识库基本概念</h1><h2 id="什么是-RAG"><a href="#什么是-RAG" class="headerlink" title="什么是 RAG?"></a>什么是 RAG?</h2><p>RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索技术和 AI 内容生成的混合架构，可以解决大模型的知识时效性限制和幻觉问题。</p>
<p>使用 RAG 的大模型应用在生成回答之前，会先从外部知识库种检索相关信息，然后将<strong>这些检索到的内容作为额外上下文提供给模型</strong>，引导其生成更准确、更相关的回答。</p>
<p>应用前景：</p>
<ul>
<li>准确回答关于特定内容的问题</li>
<li>在何时的时机推荐相关课程和服务（广告应用！！！）</li>
<li>用特定的语气和用户交流（这里其实觉得通过 Advisor 和预设 System Prompt 也可以实现效果）</li>
<li>提供更新、更准确的建议</li>
<li>小模型 + 大数据</li>
</ul>
<h2 id="RAG-工作流程"><a href="#RAG-工作流程" class="headerlink" title="RAG 工作流程"></a>RAG 工作流程</h2><p>主要包含 4 个核心步骤：</p>
<ul>
<li>文档收集和切割</li>
<li>向量转换和存储</li>
<li>文档过滤和检索</li>
<li>查询增强和关联</li>
</ul>
<h3 id="1、文档收集和切割（ETL）"><a href="#1、文档收集和切割（ETL）" class="headerlink" title="1、文档收集和切割（ETL）"></a>1、文档收集和切割（ETL）</h3><p>文档收集和预处理涉及 Extract、Transformer、Load 三部分，从各种途径收集并预处理，降低文件冗余，转换成标准化文本格式（推荐Markdown而不是pdf）。</p>
<p>文档切割：将长文档分割成适当大小的片段（俗称 chunks，这个是作为开发者的重点关注对象）</p>
<ul>
<li>基于固定大小（如 512 个 token）</li>
<li>基于语义边界（如段落、章节）</li>
<li>基于递归分割策略（如递归字符 n-gram 切割）</li>
</ul>
<p>实际开发中，推荐基于语义边界 + LLM 辅助分割，并且增加标签 metadata 来辅助检索。仅基于固定大小的切割效果并不好。</p>
<h3 id="2、向量转换和存储"><a href="#2、向量转换和存储" class="headerlink" title="2、向量转换和存储"></a>2、向量转换和存储</h3><p>向量转换：使用 Embedding 模型将文本块转换为高维向量表示，可以捕获到文本的语义特征；</p>
<p>向量存储：将生成的向量和对应文本存入向量数据库，支持高效的相似性搜索。</p>
<p>本质上是语义特征的相似性匹配，高维向量是另一种更凝练的信息标签。</p>
<h3 id="3、文档过滤和检索"><a href="#3、文档过滤和检索" class="headerlink" title="3、文档过滤和检索"></a>3、文档过滤和检索</h3><p>查询处理：将用户问题也转换为向量表示；</p>
<p>过滤机制：基于元数据 metadata、关键词或自定义规则进行过滤；</p>
<p>相似度搜索：在向量数据库中查找与问题向量最相似的文档块，常用的相似度算法有余弦相似度、欧氏距离等；</p>
<p>上下文组装：将检索到的多个文档块组装成连贯上下文。</p>
<h3 id="4、查询增强和关联"><a href="#4、查询增强和关联" class="headerlink" title="4、查询增强和关联"></a>4、查询增强和关联</h3><p>提示词组装：将检索到的相关文档与用户问题组合成增强提示</p>
<p>上下文融合：大模型基于增强提示生成回答</p>
<p>源引用：在回答中添加信息来源引用</p>
<p>后处理：格式化、摘要或其他处理以优化最终输出</p>
<h3 id="完整工作流程"><a href="#完整工作流程" class="headerlink" title="完整工作流程"></a>完整工作流程</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/image/RAG-%E7%9F%A5%E8%AF%86%E5%BA%93/1769050980111.png"
                      alt="1769050980111"
                ></p>
<h2 id="RAG-相关技术"><a href="#RAG-相关技术" class="headerlink" title="RAG 相关技术"></a>RAG 相关技术</h2>]]></content>
  </entry>
  <entry>
    <title>Redis初印象</title>
    <url>/2025/07/04/Redis%E5%88%9D%E5%8D%B0%E8%B1%A1/</url>
    <content><![CDATA[<p>在求职的准备阶段中，看到很多朋友都说要准备Redis（Remote Dictionary Server），我才开始学习。然后了解到的第一个印象是写缓存，另一个印象是键值数据库（类似于Bigtable的数据库，但是区别于MySQL的关系型数据库）。我通过极客时间的 <em>Redis 核心技术与实战</em>来学习，建立了对于Redis的第一印象。这篇笔记就是整理自己对于Redis的理解。</p>
<h2 id="Redis知识全景图">Redis知识全景图</h2>
<p>Redis的知识全景图包括了“两大维度、三大系统”：</p>
<ul>
<li>应用维度：缓存应用、集群应用、数据结构应用</li>
<li>系统维度：
<ul>
<li>高性能主线：（单线程模型、数据结构、AOF、Epoll网络架构）</li>
<li>高可用主线：（主从复制、哨兵机制、RDB）</li>
<li>高可扩展主线：（数据分片、负载均衡）</li>
</ul>
</li>
</ul>
<p>联系到之前学习的计算机知识里面，在第一次学习时我分为了四个模块 。</p>
<ol>
<li>数据结构：Redis数据类型有String、List、Hash、Set和Sorted Set共五个。其底层实现上有简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。其中哈希表采用的是链式方法来解决哈希冲突的问题，而压缩列表和跳表是我比较关注的数据结构（在其他地方见到的比较少）。</li>
<li>单线程开发：并发开发讨论的一般都是多线程问题，而在这里Redis利用了作为内存数据库的优势，反而使用单线程达到了高性能的优势。</li>
<li>高可用性：日志问题，使用AOF文件日志和RDB快照来保证数据在宕机之后保持可恢复性。</li>
<li>分布式架构：分布式架构涉及到了Redis的高可用性和高可扩展性。Redis采用的是一主多从，主库和从库都可以读取数据，主库可以写入 修改数据，同时哨兵集群（形同监工）负责整体数据库的监控、选主和通知。而对于数据库的可扩展性，采用横向扩展即数据切片的方式，由多个Hash Slot和Redis实例来负责数据的存储，此时就会涉及到负载均衡的问题。（在学习分布式架构的时候，我现在习惯去和GFS的单Master架构（GFS好像就是多了一个单节点负责管理数据切片的，对于单节点的哨兵机制和这里很像），还有MySQL的主从架构去比较，感觉有很多相似之处）</li>
</ol>
<h2 id="数据结构">数据结构</h2>
<h3 id="键值对数据结构">键值对数据结构</h3>
<p>首先，需要学习的是Redis是一种键值数据库，Redis使用了一个哈希表来保存所有键值对。一个哈希表就是一个数组，数组的每个元素称为一个哈希桶。哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。哈希桶中的 entry 元素中保存了key和value指针，分别指向了实际的键和值，这样一来，即使值是一个集合，也可以通过*value指针被查找到。</p>
<p>当哈希表由于太小而导致链过长了之后，会进行rehash来扩容。在具体的实现上，Redis默认使用两个全局哈希表。一开始使用哈希表1，而哈希表2没有分配额外的空间，当需要进行rehash的时候。为哈希表2分配大于哈希表1的空间，然后把哈希表1的数据重新映射到哈希表2中，之后释放哈希表1的空间并留作下一次扩容使用。不过由于一次全量复制会造成Redis线程阻塞，所以Redis采用渐进式rehash，即处理一次请求再处理一个索引下的entries的重映射复制（这里很像AOF的重写，不过是把大文件变成小文件）</p>
<h3 id="Value数据结构">Value数据结构</h3>
<p>键值对中值的数据结构有&quot;String、List、Hash、Set、Sorted Set&quot;，其底层的数据结构对应如下：</p>
<ul>
<li>String字符串：简单动态字符串</li>
<li>List列表：双向链表、压缩列表</li>
<li>Hash哈希：哈希表、压缩列表</li>
<li>Sorted Set集合：跳表、压缩列表</li>
<li>Set有序集：哈希表、整数数组</li>
</ul>
<p>String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下，我们会把这四种类型称为集合类型，它们的特点是一个键对应了一个集合的数据。</p>
<p>可以见到，集合的底层数据结构包括五个：双向链表、压缩列表、哈希表、跳表和整数数组。其中整数数组、哈希表和双向链表都比较熟悉，这里着重记录一下压缩列表和跳表。</p>
<h4 id="压缩列表">压缩列表</h4>
<p>压缩列表的思想会让我想到网络传输里面TCP的数据头，或者JAVA并发开发里面线程的数据头，本质是就是在数据上增加描述数据的信息。压缩列表在表头有三个字段，zlbytes、zltail和zllen，在尾部有zlend。</p>
<p>其中，zlbytes：整个压缩列表占用的内存字节数。 zltail：从压缩列表起始地址到最后一个节点的字节数。 zllength：压缩列表包含的节点个数。 entries：一系列节点，每个节点代表一个键值对或者列表项。 zlend：特殊值0xFF，表示压缩列表的结束标志。</p>
<p><strong>应用场景</strong>：在列表、散列和有序集合的长度较短或者体积较小的时候，Redis可以选择使用一种名为压缩列表（ziplist）的紧凑存储方式来存储这些结构。压缩列表是列表、散列和有序集合这3种不同类型的对象的一种非结构化（unstructured）表示：与Redis在通常情况下使用双链表表示列表、使用散列表表示散列、使用散列表加上跳跃表（skiplist）表示有序集合的做法不同，压缩列表会以序列化的方式存储数据，这些序列化数据每次被读取的时候都要进行解码，每次被写入的时候也要进行局部的重新编码，并且可能需要对内存里面的数据进行移动。压缩列表的设计不是为了查询的，而是为了减少内存的使用和内存的碎片化。</p>
<h4 id="跳表">跳表</h4>
<p>因为有序链表的按序查找非常慢，所以设计了跳表这个数据结构。跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。查找的时间复杂度是O(log(N))</p>
<h3 id="不同操作的复杂度">不同操作的复杂度</h3>
<p>直接记录原书的“四句口诀”：</p>
<ul>
<li>单元素操作是基础；（对单元素的增删改查，普遍都是O(1)）</li>
<li>范围操作非常耗时；（遍历操作，复杂度普遍为O(N)）</li>
<li>统计操作通常高效；（因为数据结构中一般都有记录元素个数所以高效）</li>
<li>例外情况只有几个。（压缩列表和双向链表都会记录表头和表尾的偏移量，在头尾的操作高效）</li>
</ul>
<h2 id="高性能IO模型">高性能IO模型</h2>
<p>我在思考这个问题的时候首先想到的是并发开发（原书也是这么提的），因为一般程序都会考虑通过多线程并发开发来缓和CPU寄存器、Cache、内存和磁盘之间数据读写速度不一致导致的资源浪费问题。但是Redis却反其道而行选择用单线程，所以我觉得这里是一个重点。</p>
<h3 id="为什么多线程不行">为什么多线程不行</h3>
<p>多线程的缺点就在于对共享资源的访问上，为了保持一致性，常需要锁等手段来保证安全访问，增加了额外的开销。如果锁的设计出现问题，即使增加了线程，大部分线程都在等待获取访问共享资源的互斥锁，并行变成串行。因此，Redis选择直接采用单线程模型，简化代码增加可维护性。</p>
<h3 id="单线程Redis为什么那么快">单线程Redis为什么那么快</h3>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/10/15/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a class="link"   href="https://hexo.io/" >Hexo <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>! This is your very first post. Check <a class="link"   href="https://hexo.io/docs/" >documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> for more info. If you get any problems when using Hexo, you can find the answer in <a class="link"   href="https://hexo.io/docs/troubleshooting.html" >troubleshooting <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> or you can ask me on <a class="link"   href="https://github.com/hexojs/hexo/issues" >GitHub <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>.</p>
<h2 id="Quick-Start">Quick Start</h2>
<h3 id="Create-a-new-post">Create a new post</h3>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure></div>
<p>More info: <a class="link"   href="https://hexo.io/docs/writing.html" >Writing <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="Run-server">Run server</h3>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure></div>
<p>More info: <a class="link"   href="https://hexo.io/docs/server.html" >Server <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="Generate-static-files">Generate static files</h3>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure></div>
<p>More info: <a class="link"   href="https://hexo.io/docs/generating.html" >Generating <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure></div>
<p>More info: <a class="link"   href="https://hexo.io/docs/one-command-deployment.html" >Deployment <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
]]></content>
  </entry>
  <entry>
    <title>一个Java程序的从生到死</title>
    <url>/2025/06/11/%E4%B8%80%E4%B8%AAJava%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%BB%8E%E7%94%9F%E5%88%B0%E6%AD%BB/</url>
    <content><![CDATA[<p>在学习Java的时候，一个重点就是学习如何实现它如何实现&quot;Write Once, Run anywhere&quot;。而这其中的一个重点就是计算机运行Java的流程，其如何将.java文件转换成.class文件再到计算机底层CPU可以识别的二进制文件。在第一个转换中，涉及到了JDK中的javac组件，属于Java前端编译中的一部分；在第二个转换中，则涉及到了JVM的诸多细节，如执行引擎中的JIT Compiler即时编译、Garbage Collect垃圾回收，Java运行时数据区的VM stack、方法区、程序计数器PC等等细节的实现。我力图在整理Java程序运行的流程中，梳理好从javac到JVM中的每一步细节，可以将知识点连接起来。</p>
<h2 id="前端编译：-java到-class">前端编译：.java到.class</h2>
<p>javac(JDK内部，JVM外部)</p>
<p>对于JVM来说，实际的输入是字节码文件，但是我们写好的是Java文件。所以我们需要通过javac来讲Java文件编译成字节码文件然后再传入JVM中。具体的步骤包括如下：程序源码-&gt;词法分析-&gt;单词流-&gt;语法分析（将Token流转换成AST）-&gt;抽象语法树-&gt;语义分析器-&gt;注解抽象语法树-&gt;字节码生成器-&gt;JVM字节码，这称之为前端编译。</p>
<p>抽象语法树（AST）：反映代码的语法结构（如运算符、变量名、表达式嵌套等），由语法分析阶段生成。</p>
<p>注解抽象语法树：在原始AST的基础上，通过语义分析添加了语义信息，例如：变量/方法的数据类型（如b是int还是String）、符号的作用域（如b是局部变量还是类字段）、表达式的合法性（如b + 1是否类型兼容）。</p>
<ul>
<li><strong>词法分析</strong>：解决“是什么单词”的问题。</li>
<li><strong>语法分析</strong>：解决“单词如何组合”的问题。</li>
<li><strong>语义分析</strong>：解决“组合是否有意义”的问题。</li>
</ul>
<h2 id="JVM编译阶段（解释器-JIT-Compiler）：-class到机器指令">JVM编译阶段（解释器&amp;JIT Compiler）：.class到机器指令</h2>
<p>（JVM内部）</p>
<p>JVM阶段的输入是字节码文件而非源文件，这种设置就是为了“write once, run anywhere”。因为如C语言，因为需要设计到一些具体的函数与操作系统相关，不同的操作系统对应的函数就需要修改。而对于字节码来说，JVM的存在可以承担起对于每个平台的适配性。解释器就是将字节码文件中的内容“翻译”为对应平台的本地机器指令去执行。</p>
<p>解释器承担了主要的编译工作，而JIT Compiler是一种针对hotspot的优化机制，所以说Java是一种半解释半编译的语言。</p>
<h3 id="解释器的分类">解释器的分类</h3>
<p>字节码解释器 &amp; 模板解释器</p>
<p>字节码解释器：需要在执行代码时通过纯软件代码模拟字节码的执行，效率十分低；</p>
<p>模板解释器：每一条字节码和一个模板函数相关联，模板函数中直接产生这条字节码执行时的机器码，能提高性能。</p>
<ul>
<li>Hotspot中，解释器主要有Intepreter模块和Code模块。
<ul>
<li>Intepreter模块：实现了解释器的核心功能；</li>
<li>Code模块：用于管理Hotspot在运行时生成的本地机器指令。</li>
</ul>
</li>
</ul>
<h3 id="JIT-Compiler">JIT Compiler</h3>
<p>JIT编译器，Just In Time Compiler，又名即时编译器。根据它，JVM可将源代码直接编译为和本地机器平台相关的机器语言指令。</p>
<p>Hotspot虚拟机采用二者并存的方式，在jvm执行过程中，二者相互协助，取长补短。在jvm启动的时候，解释器先发挥作用，随着程序运行时间的推移，即时编译器发挥作用，根据热点检测功能，将有价值的字节码编译为本地机器指令，以换取更高的执行效率。</p>
<p>通过jconsole的vm模块可以看到使用JIT Compiler的情况。</p>
<h3 id="后端编译优化">后端编译优化</h3>
<p>Hotspot code “热点代码”：当虚拟机发现某个方法或代码块的运行特别频繁，就会被认为是热点代码。在运行时，虚拟机会把这些代码编译为本地机器码，并尽可能地优化。</p>
]]></content>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
</search>
